{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rQ9yqa7YSLkA"
      },
      "outputs": [],
      "source": [
        "# Importing the required packages\n",
        "from sklearn.datasets import make_regression\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Dz9zOuPxSs7H"
      },
      "outputs": [],
      "source": [
        "# Initialising the spark session\n",
        "spark = SparkSession.builder\\\n",
        "                    .appName(\"RegressionExample\")\\\n",
        "                    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XxSwZfvrSvwr"
      },
      "outputs": [],
      "source": [
        "# Creating the regression dataset with 10_000 rows and 5 columns\n",
        "X, y = make_regression(n_samples = 10_000, n_features = 4, noise = 10, random_state = 7)\n",
        "\n",
        "data = [(float(X[i, 0]), float(X[i, 1]), float(X[i, 2]), float(X[i, 3]), float(y[i])) for i in range(len(X))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zRrQ-nMCSz9F"
      },
      "outputs": [],
      "source": [
        "# Creating the Spark Dataframe\n",
        "spark_df = spark.createDataFrame(data, [\"Feature 1\", \"Feature 2\", \"Feature 3\", \"Feature 4\", \"Target\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBhXvXLUUtI3",
        "outputId": "23e5d09e-e7a4-4266-f4a6-189fa54e4908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Feature 1', 'Feature 2', 'Feature 3', 'Feature 4', 'Target']\n"
          ]
        }
      ],
      "source": [
        "# Printing the column names of the dataset\n",
        "print(spark_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnGPF14PVBuj",
        "outputId": "38808e95-e1e5-4cc5-8933-2fecd29961b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Feature 1: double (nullable = true)\n",
            " |-- Feature 2: double (nullable = true)\n",
            " |-- Feature 3: double (nullable = true)\n",
            " |-- Feature 4: double (nullable = true)\n",
            " |-- Target: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Printing the schema of each columns\n",
        "spark_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwzGnb-IVL5C",
        "outputId": "84653384-6bb6-44b6-a32d-30c5a1410a24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
            "|summary|           Feature 1|           Feature 2|           Feature 3|           Feature 4|             Target|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
            "|  count|               10000|               10000|               10000|               10000|              10000|\n",
            "|   mean|0.002544132739425...|-0.01451103179417...|0.009994074793825022|-0.00527202077587...|-0.5945901595480387|\n",
            "| stddev|   0.994910756457706|  0.9905901068781727|  0.9925380827115298|  0.9951669116152843| 113.06668726241749|\n",
            "|    min|  -4.114495828487157| -3.6714407164475813| -3.8480111366237453| -3.4156615653390623| -448.1156168306303|\n",
            "|    25%| -0.6694742894547767| -0.6718483340586358| -0.6582615623787684| -0.6710175711541245| -75.83562881697048|\n",
            "|    50%|0.006222023298174971|-0.00436592371459...|0.007047689107622504| 0.00631565280995182|-2.1076805888741603|\n",
            "|    75%|   0.665085190940703|  0.6457282284248467|  0.6904330025812545|  0.6625252858892835|  75.88805888805267|\n",
            "|    max|   3.851750403579486|  3.4134767922556377|   3.742891152887434|  3.7276914687375764|   417.689671652246|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Printing the summary of the columns\n",
        "spark_df.summary().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4mLveOXdVm31"
      },
      "outputs": [],
      "source": [
        "# Randomly splitting the dataset into train and test dataset\n",
        "train_data, test_data = spark_df.randomSplit([0.8, 0.2], seed = 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eV1SH8TDWubC"
      },
      "outputs": [],
      "source": [
        "# Combining features into a single vector column\n",
        "assembler = VectorAssembler(inputCols = [\"Feature 1\", \"Feature 2\", \"Feature 3\", \"Feature 4\"],\n",
        "                            outputCol = \"features\")\n",
        "\n",
        "train_data = assembler.transform(train_data)\n",
        "test_data = assembler.transform(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UsXUIxMHXP_q"
      },
      "outputs": [],
      "source": [
        "# Training the linear regression model\n",
        "lr = LinearRegression(featuresCol = \"features\", labelCol = \"Target\")\n",
        "model = lr.fit(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Tv7X_-HtXbMs"
      },
      "outputs": [],
      "source": [
        "# Making the predictions on the test data\n",
        "predictions = model.transform(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhMDy-vqXhc3",
        "outputId": "7c5832a6-138a-437e-d1cf-e0c877fa6849"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE score for the model is: 100.30719796366067\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the model using MSE and r2 score\n",
        "evaluater = RegressionEvaluator(labelCol = \"Target\", predictionCol =\"prediction\", metricName = \"mse\")\n",
        "mse = evaluater.evaluate(predictions)\n",
        "\n",
        "print(f\"MSE score for the model is: {mse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UJ_ksVwYBet",
        "outputId": "d9572f7c-8c42-4439-9a7d-f319092bc96e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "r2 score of the model is: 0.9923060623080251\n"
          ]
        }
      ],
      "source": [
        "r2 = model.summary.r2\n",
        "\n",
        "print(f\"r2 score of the model is: {r2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDOZ_TCOa6b4"
      },
      "source": [
        "- **make_regression** function generates simulated regression data for model testing.\n",
        "- **LinearRegression** represents a linear regression model in PySpark.\n",
        "- **RegressionEvaluator** is used to evaluate the model's performance.\n",
        "- **VectorAssembler** is used to assemble the input features into a single vector column.\n",
        "- **SparkSession** is used to create a SparkSession, which is the entry point for working with DataFrames in PySpark."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
